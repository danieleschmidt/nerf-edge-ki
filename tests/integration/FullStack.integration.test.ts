/**\n * Full-stack integration tests for NeRF Edge Kit\n * Tests the complete workflow from model loading to rendering\n */\n\nimport { initialize, quickStart, createDemoScene, dispose } from '../../src/index';\nimport { NerfRenderer } from '../../src/rendering/NerfRenderer';\nimport { NerfService } from '../../src/services/NerfService';\nimport { PerformanceService } from '../../src/services/PerformanceService';\nimport { NerfScene } from '../../src/core/NerfScene';\nimport { NerfModel } from '../../src/core/NerfModel';\nimport '../../web/tests/setup';\n\n// Mock canvas for testing\nObject.defineProperty(HTMLCanvasElement.prototype, 'getContext', {\n  value: jest.fn().mockReturnValue({\n    fillRect: jest.fn(),\n    clearRect: jest.fn(),\n    drawImage: jest.fn()\n  })\n});\n\ndescribe('NeRF Edge Kit Full-Stack Integration', () => {\n  let canvas: HTMLCanvasElement;\n\n  beforeEach(() => {\n    canvas = document.createElement('canvas');\n    canvas.width = 800;\n    canvas.height = 600;\n  });\n\n  afterEach(() => {\n    dispose();\n  });\n\n  describe('SDK Initialization', () => {\n    it('should initialize complete SDK with default configuration', async () => {\n      // Act\n      const { renderer, service, performance } = await initialize();\n\n      // Assert\n      expect(renderer).toBeInstanceOf(NerfRenderer);\n      expect(service).toBeInstanceOf(NerfService);\n      expect(performance).toBeInstanceOf(PerformanceService);\n    });\n\n    it('should initialize with custom configuration', async () => {\n      // Arrange\n      const config = {\n        targetFPS: 90,\n        maxResolution: [2560, 1440] as [number, number],\n        foveatedRendering: true,\n        memoryLimit: 2048,\n        powerMode: 'performance' as const\n      };\n\n      // Act\n      const { renderer, service, performance } = await initialize(config);\n\n      // Assert\n      expect(renderer).toBeInstanceOf(NerfRenderer);\n      expect(service).toBeInstanceOf(NerfService);\n      expect(performance).toBeInstanceOf(PerformanceService);\n    });\n\n    it('should provide global SDK access after initialization', async () => {\n      // Act\n      const { renderer } = await initialize();\n      const { getSDK } = await import('../../src/index');\n      const globalSDK = getSDK();\n\n      // Assert\n      expect(globalSDK.renderer).toBe(renderer);\n      expect(globalSDK.service).toBeInstanceOf(NerfService);\n      expect(globalSDK.performance).toBeInstanceOf(PerformanceService);\n    });\n  });\n\n  describe('Quick Start Workflow', () => {\n    it('should complete quick start workflow', async () => {\n      // Act\n      const { renderer, scene, service } = await quickStart(canvas);\n\n      // Assert\n      expect(renderer).toBeInstanceOf(NerfRenderer);\n      expect(scene).toBeInstanceOf(NerfScene);\n      expect(service).toBeInstanceOf(NerfService);\n      expect(scene.isSceneLoaded()).toBe(true);\n      expect(scene.getVisibleModels().length).toBeGreaterThan(0);\n    });\n\n    it('should work without canvas', async () => {\n      // Act\n      const { renderer, scene, service } = await quickStart();\n\n      // Assert\n      expect(renderer).toBeInstanceOf(NerfRenderer);\n      expect(scene).toBeInstanceOf(NerfScene);\n      expect(service).toBeInstanceOf(NerfService);\n    });\n  });\n\n  describe('Demo Scene Creation', () => {\n    it('should create demo scene with mock models', async () => {\n      // Act\n      const scene = await createDemoScene();\n\n      // Assert\n      expect(scene).toBeInstanceOf(NerfScene);\n      expect(scene.isSceneLoaded()).toBe(true);\n      expect(scene.getVisibleModels().length).toBe(3);\n      expect(scene.getConfig().name).toBe('Demo Scene');\n    });\n\n    it('should have properly positioned models', async () => {\n      // Act\n      const scene = await createDemoScene();\n      const models = scene.getVisibleModels();\n\n      // Assert\n      expect(models).toHaveLength(3);\n      expect(models[0].id).toBe('center');\n      expect(models[1].id).toBe('left');\n      expect(models[2].id).toBe('right');\n      \n      // Check positioning\n      expect(models[0].transform.position).toEqual([0, 0, 0]);\n      expect(models[1].transform.position).toEqual([-3, 0, 0]);\n      expect(models[2].transform.position).toEqual([3, 0, 0]);\n    });\n  });\n\n  describe('End-to-End Model Workflow', () => {\n    let service: NerfService;\n    let renderer: NerfRenderer;\n    let performance: PerformanceService;\n\n    beforeEach(async () => {\n      const sdk = await initialize();\n      service = sdk.service;\n      renderer = sdk.renderer;\n      performance = sdk.performance;\n      \n      await renderer.initialize(canvas);\n    });\n\n    it('should complete full model lifecycle', async () => {\n      // 1. Create mock model data\n      const mockModelData = new ArrayBuffer(4096);\n      \n      // 2. Load model\n      const model = await service.loadModel(mockModelData, 'lifecycle-test');\n      expect(model).toBeInstanceOf(NerfModel);\n      expect(model.isModelLoaded()).toBe(true);\n      \n      // 3. Analyze model\n      const metrics = await service.analyzeModel('lifecycle-test');\n      expect(metrics.psnr).toBeGreaterThan(0);\n      expect(metrics.ssim).toBeGreaterThan(0);\n      \n      // 4. Optimize model\n      const optimizedModel = await service.optimizeModel('lifecycle-test', {\n        targetDevice: 'web',\n        maxLatency: 6.5,\n        maxMemory: 256,\n        minQuality: 0.85,\n        enableQuantization: true,\n        enablePruning: true\n      });\n      expect(optimizedModel).toBeInstanceOf(NerfModel);\n      \n      // 5. Create scene with model\n      const scene = service.createScene(['lifecycle-test']);\n      expect(scene.isSceneLoaded()).toBe(true);\n      \n      // 6. Setup renderer with scene\n      renderer.setScene(scene);\n      \n      // 7. Start performance monitoring\n      performance.startMonitoring(() => renderer.getPerformanceMetrics());\n      \n      // 8. Render frames\n      await renderer.render({\n        cameraPosition: [0, 1.6, 3],\n        cameraRotation: [0, 0, 0, 1],\n        fieldOfView: 75,\n        near: 0.1,\n        far: 100\n      });\n      \n      // 9. Stop monitoring and get stats\n      performance.stopMonitoring();\n      const stats = performance.getCurrentStats();\n      expect(stats.current).toBeDefined();\n      \n      // 10. Cleanup\n      service.clearCache();\n      const cacheStats = service.getCacheStats();\n      expect(cacheStats.totalModels).toBe(0);\n    });\n\n    it('should handle multiple models in scene', async () => {\n      // Create multiple models\n      const modelIds = [];\n      for (let i = 0; i < 3; i++) {\n        const mockData = new ArrayBuffer(2048 * (i + 1));\n        const model = await service.loadModel(mockData, `multi-test-${i}`);\n        expect(model.isModelLoaded()).toBe(true);\n        modelIds.push(`multi-test-${i}`);\n      }\n      \n      // Create scene with all models\n      const scene = service.createScene(modelIds, {\n        name: 'Multi-Model Scene',\n        lighting: {\n          ambient: [0.2, 0.2, 0.25]\n        }\n      });\n      \n      expect(scene.getVisibleModels()).toHaveLength(3);\n      expect(scene.getConfig().name).toBe('Multi-Model Scene');\n      \n      // Test scene operations\n      scene.setModelVisibility('multi-test-1', false);\n      expect(scene.getVisibleModels()).toHaveLength(2);\n      \n      scene.setModelOpacity('multi-test-0', 0.5);\n      const model0 = scene.getModel('multi-test-0');\n      expect(model0?.opacity).toBe(0.5);\n    });\n\n    it('should handle training workflow', async () => {\n      // Create mock point cloud data\n      const pointCloudData = new ArrayBuffer(8192);\n      \n      // Track training progress\n      const progressUpdates: number[] = [];\n      const progressCallback = (progress: number) => {\n        progressUpdates.push(progress);\n      };\n      \n      // Train model\n      const trainedModel = await service.trainModel(pointCloudData, {\n        iterations: 100,\n        learningRate: 0.001,\n        batchSize: 4096,\n        useNeuralEngine: false,\n        checkpoint_interval: 50\n      }, progressCallback);\n      \n      expect(trainedModel).toBeInstanceOf(NerfModel);\n      expect(trainedModel.isModelLoaded()).toBe(true);\n      expect(progressUpdates.length).toBeGreaterThan(0);\n      expect(progressUpdates[progressUpdates.length - 1]).toBe(1.0);\n      \n      // Analyze trained model\n      const modelId = `trained_${Date.now()}`;\n      await service.loadModel(new ArrayBuffer(1024), modelId); // Mock load\n      const metrics = await service.analyzeModel(modelId);\n      expect(metrics).toBeDefined();\n    });\n  });\n\n  describe('Performance Integration', () => {\n    let renderer: NerfRenderer;\n    let performance: PerformanceService;\n\n    beforeEach(async () => {\n      const { renderer: r, performance: p } = await initialize({\n        targetFPS: 60,\n        maxResolution: [1280, 720],\n        powerMode: 'balanced'\n      });\n      \n      renderer = r;\n      performance = p;\n      await renderer.initialize(canvas);\n    });\n\n    it('should monitor performance during rendering', async () => {\n      // Setup scene\n      const scene = await createDemoScene();\n      renderer.setScene(scene);\n      \n      // Start monitoring\n      performance.startMonitoring(() => ({\n        fps: 60 + Math.random() * 10,\n        frameTime: 16.7 + Math.random() * 2,\n        gpuUtilization: 0.6 + Math.random() * 0.2,\n        memoryUsage: 300 + Math.random() * 100,\n        powerConsumption: 4 + Math.random() * 2\n      }), 50);\n      \n      // Wait for some samples\n      await new Promise(resolve => setTimeout(resolve, 200));\n      \n      // Stop monitoring\n      performance.stopMonitoring();\n      \n      // Check collected data\n      const stats = performance.getCurrentStats();\n      expect(stats.current.fps).toBeGreaterThan(0);\n      expect(stats.averages.fps).toBeGreaterThan(0);\n      \n      const recommendations = performance.getRecommendations();\n      expect(Array.isArray(recommendations)).toBe(true);\n    });\n\n    it('should run performance benchmarks', async () => {\n      // Setup\n      const scene = await createDemoScene();\n      renderer.setScene(scene);\n      \n      // Run benchmark\n      const result = await performance.runBenchmark(\n        'Full Stack Benchmark',\n        0.2,\n        () => ({\n          fps: 50 + Math.random() * 20,\n          frameTime: 16 + Math.random() * 8,\n          gpuUtilization: 0.5 + Math.random() * 0.4,\n          memoryUsage: 400 + Math.random() * 200,\n          powerConsumption: 5 + Math.random() * 3\n        })\n      );\n      \n      expect(result.testName).toBe('Full Stack Benchmark');\n      expect(result.averageFPS).toBeGreaterThan(0);\n      expect(result.qualityScore).toBeGreaterThanOrEqual(0);\n      expect(result.qualityScore).toBeLessThanOrEqual(1);\n    });\n  });\n\n  describe('Error Handling and Edge Cases', () => {\n    it('should handle initialization failures gracefully', async () => {\n      // Mock WebGPU not supported\n      Object.defineProperty(navigator, 'gpu', {\n        value: undefined,\n        configurable: true\n      });\n      \n      // Act & Assert\n      await expect(initialize()).rejects.toThrow();\n      \n      // Restore\n      Object.defineProperty(navigator, 'gpu', {\n        value: {\n          requestAdapter: jest.fn().mockResolvedValue({\n            requestDevice: jest.fn().mockResolvedValue({\n              createShaderModule: jest.fn(),\n              createRenderPipeline: jest.fn(),\n              createBuffer: jest.fn(),\n              queue: { submit: jest.fn() }\n            })\n          })\n        },\n        configurable: true\n      });\n    });\n\n    it('should handle resource disposal properly', async () => {\n      // Initialize\n      const { renderer, service, performance } = await initialize();\n      await renderer.initialize(canvas);\n      \n      // Use resources\n      const scene = await createDemoScene();\n      renderer.setScene(scene);\n      performance.startMonitoring(() => renderer.getPerformanceMetrics());\n      \n      // Dispose\n      expect(() => dispose()).not.toThrow();\n      \n      // Verify cleanup\n      const { getSDK } = await import('../../src/index');\n      const globalSDK = getSDK();\n      expect(globalSDK.renderer).toBeNull();\n      expect(globalSDK.service).toBeNull();\n      expect(globalSDK.performance).toBeNull();\n    });\n\n    it('should handle multiple initialization calls', async () => {\n      // First initialization\n      const sdk1 = await initialize();\n      \n      // Second initialization should not conflict\n      const sdk2 = await initialize();\n      \n      expect(sdk1.renderer).toBeInstanceOf(NerfRenderer);\n      expect(sdk2.renderer).toBeInstanceOf(NerfRenderer);\n      \n      // Both should be valid but different instances\n      expect(sdk1.renderer).not.toBe(sdk2.renderer);\n    });\n  });\n\n  describe('Memory Management', () => {\n    it('should properly manage memory across operations', async () => {\n      const { service } = await initialize();\n      \n      // Load multiple models\n      const modelIds = [];\n      for (let i = 0; i < 5; i++) {\n        const mockData = new ArrayBuffer(1024 * (i + 1));\n        const model = await service.loadModel(mockData, `memory-test-${i}`);\n        expect(model.isModelLoaded()).toBe(true);\n        modelIds.push(`memory-test-${i}`);\n      }\n      \n      // Check memory usage\n      let stats = service.getCacheStats();\n      expect(stats.totalModels).toBe(5);\n      expect(stats.totalMemory).toBeGreaterThan(0);\n      \n      // Clear cache\n      service.clearCache();\n      stats = service.getCacheStats();\n      expect(stats.totalModels).toBe(0);\n      expect(stats.totalMemory).toBe(0);\n    });\n\n    it('should handle large model operations', async () => {\n      const { service } = await initialize();\n      \n      // Create large model\n      const largeModelData = new ArrayBuffer(5 * 1024 * 1024); // 5MB\n      const model = await service.loadModel(largeModelData, 'large-model');\n      \n      expect(model.isModelLoaded()).toBe(true);\n      expect(model.getMemoryUsage()).toBeGreaterThan(5 * 1024 * 1024);\n      \n      // Optimize for memory\n      const optimized = await service.optimizeModel('large-model', {\n        targetDevice: 'web',\n        maxLatency: 10,\n        maxMemory: 256,\n        minQuality: 0.8,\n        enableQuantization: true,\n        enablePruning: true\n      });\n      \n      expect(optimized.getMemoryUsage()).toBeLessThan(model.getMemoryUsage());\n    });\n  });\n});